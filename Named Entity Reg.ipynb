{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Named Entity Reg.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"Dqy7LQZmbu-9","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","import gensim\n","import numpy as np\n","import math"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wIWT_Nl5bu_D","colab_type":"code","colab":{}},"cell_type":"code","source":["corpus = open('train.txt',encoding=\"utf8\").readlines()\n","text_corpus = open('valid.txt',encoding=\"utf8\").readlines()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yydYH_APjKzR","colab_type":"code","colab":{}},"cell_type":"code","source":["def word2vec(corpus):\n","  sentence = []\n","  point = []\n","  for line in corpus:\n","      stripped_line = line.strip().split(' ')\n","      point.append(stripped_line)\n","      if line == '\\n':\n","          sentence.append(point[:-1])\n","          point = []\n","  sentence = sentence[:-1]\n","  text_sentence = [[c[0] for c in x1]for x1 in sentence]\n","  tags = [[c[-1] for c in y] for y in sentence]\n","  list_sequence_length = [len(s) for s in sentence]\n","  #build word2vec model\n","  model = gensim.models.Word2Vec(text_sentence,size=150,window=10,min_count=1,workers=10)\n","  model.train(text_sentence, total_examples=len(text_sentence), epochs=10)\n","  return model,text_sentence,tags,list_sequence_length"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kSPOnT83bu_S","colab_type":"code","colab":{}},"cell_type":"code","source":["def encode_tag(tag):\n","    if 'B-MISC' in tag:\n","        return 1\n","    elif 'I-MISC' in tag:\n","        return 2\n","    elif 'B-PER' in tag:\n","        return 3\n","    elif 'I-PER' in tag:\n","        return 4\n","    elif 'B-LOC' in tag:\n","        return 5\n","    elif 'I-LOC' in tag:\n","        return 6\n","    elif 'B-ORG' in tag:\n","        return 7\n","    elif 'I-ORG' in tag:\n","        return 8\n","    else:\n","        return 0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jX7mDPTUMWYc","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"JnUvH051bu_V","colab_type":"code","colab":{}},"cell_type":"code","source":["def pad(sentence, max_length,dim,isTg = False):\n","    pad_len = max_length - len(sentence)\n","    padding = np.zeros(pad_len)\n","    if isTg == False:\n","        padding = [np.zeros(dim) for i in range(0,pad_len)]\n","    return np.concatenate((sentence, padding))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MxMcXLeUSKPL","colab_type":"code","outputId":"355e4c9b-aa20-4d2f-960d-786ff784d1c9","executionInfo":{"status":"ok","timestamp":1541748358474,"user_tz":-420,"elapsed":758,"user":{"displayName":"Syaoran Clone","photoUrl":"https://lh5.googleusercontent.com/-z50jZxTK8Js/AAAAAAAAAAI/AAAAAAAAADM/pUn0TaeAECU/s64/photo.jpg","userId":"11466975508847902953"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["len(list_sequence_length_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14986"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"YqWhcsfMbu_Z","colab_type":"code","colab":{}},"cell_type":"code","source":["def batch(data,labels,batch_size,sequence_length):\n","    n_batch = int(math.ceil(14986/batch_size)) # 14986 is number of sentence in X_trains\n","    index = 0\n","    for _ in range(n_batch):\n","        batch_sequence_lengths = np.array(sequence_length[index:index+batch_size])\n","        if(batch_sequence_lengths.size > 0):\n","            max_sequence_length_in_batch = max(batch_sequence_lengths)\n","        batch_data = np.array([x for x in data[index:index+batch_size]])\n","        batch_labels = [y for y in labels[index:index+batch_size]]\n","        index += batch_size\n","        #batch_data = batch_data.reshape(-1, max_sequence_length_in_batch, input_size)\n","        yield batch_data,batch_labels,max_sequence_length_in_batch,batch_sequence_lengths\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"i_NZUQQHbu_d","colab_type":"code","colab":{}},"cell_type":"code","source":["model,text_sentence,tags,list_sequence_length_train = word2vec(corpus)\n","test_model,test_text_sentence,test_tag,list_sequence_length_test = word2vec(text_corpus)\n","en_tag = [[encode_tag(t) for t in tag] for tag in tags]\n","en_test_tag = [[encode_tag(t) for t in tag] for tag in test_tag]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JEBLntoKbu_g","colab_type":"code","outputId":"cc69e52d-0682-4e34-f4eb-c08662e79e7d","executionInfo":{"status":"ok","timestamp":1541751565124,"user_tz":-420,"elapsed":10141,"user":{"displayName":"Syaoran Clone","photoUrl":"https://lh5.googleusercontent.com/-z50jZxTK8Js/AAAAAAAAAAI/AAAAAAAAADM/pUn0TaeAECU/s64/photo.jpg","userId":"11466975508847902953"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"cell_type":"code","source":["# Bidirectional LSTM + CRF model.\n","learning_rate = 0.001\n","training_epochs = 100\n","input_size = 150\n","label_size = 9\n","batch_size = 32\n","num_units = 128 # the number of units in the LSTM cell\n","number_of_classes = 9\n","max_length = 150\n","\n","x_trains = [pad([model[w] for w in s],max_length,input_size) for s in text_sentence]\n","x_test = [pad([test_model[w] for w in s],max_length,input_size) for s in test_text_sentence]\n","y_trains = [pad(t,max_length,input_size,True) for t in en_tag]\n","y_test = [pad(t,max_length,input_size,True) for t in en_test_tag]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  # Remove the CWD from sys.path while we load stuff.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"}]},{"metadata":{"id":"FXXbkH00bu_k","colab_type":"code","colab":{}},"cell_type":"code","source":["input_data = tf.placeholder(tf.float32, [None, None, input_size], name=\"input_data\") # shape = (batch, batch_seq_len, input_size)\n","labels = tf.placeholder(tf.int32, shape=[None, None], name=\"labels\") # shape = (batch, sentence)\n","batch_sequence_length = tf.placeholder(tf.int32) # max sequence length in batch\n","original_sequence_lengths = tf.placeholder(tf.int32, [None])\n","\n","# Scope is mandatory to use LSTMCell (https://github.com/tensorflow/tensorflow/issues/799).\n","with tf.name_scope(\"BiLSTM\"):\n","    with tf.variable_scope('forward'):\n","        lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(num_units, forget_bias=1.0, state_is_tuple=True)\n","    with tf.variable_scope('backward'):\n","        lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(num_units, forget_bias=1.0, state_is_tuple=True)\n","    (output_fw, output_bw), states = tf.nn.bidirectional_dynamic_rnn(cell_fw=lstm_fw_cell, \n","                                                                     cell_bw=lstm_bw_cell, \n","                                                                     inputs=input_data,\n","                                                                     sequence_length=original_sequence_lengths, \n","                                                                     dtype=tf.float32,\n","                                                                     scope=\"BiLSTM\")\n","\n","# As we have a Bi-LSTM, we have two outputs which are not connected, so we need to merge them.\n","outputs = tf.concat([output_fw, output_bw], axis=2)\n","\n","# Fully connected layer.\n","W = tf.get_variable(name=\"W\", shape=[2 * num_units, number_of_classes],\n","                dtype=tf.float32)\n","\n","b = tf.get_variable(name=\"b\", shape=[number_of_classes], dtype=tf.float32,\n","                initializer=tf.zeros_initializer())\n","\n","outputs_flat = tf.reshape(outputs, [-1, 2 * num_units])\n","pred = tf.matmul(outputs_flat, W) + b\n","#scores = tf.reshape(pred, [-1, batch_sequence_length, number_of_classes])\n","scores = tf.reshape(pred, [-1, tf.shape(outputs)[1], number_of_classes])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mKHQ74CXbu_q","colab_type":"code","outputId":"4f693931-5f4f-4449-8026-ada5854ec616","executionInfo":{"status":"ok","timestamp":1541751582820,"user_tz":-420,"elapsed":9060,"user":{"displayName":"Syaoran Clone","photoUrl":"https://lh5.googleusercontent.com/-z50jZxTK8Js/AAAAAAAAAAI/AAAAAAAAADM/pUn0TaeAECU/s64/photo.jpg","userId":"11466975508847902953"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"cell_type":"code","source":["# Linear-CRF.\n","#dense_y = tf.argmax(labels, -1, output_type=tf.int32)\n","log_likelihood, transition_params = tf.contrib.crf.crf_log_likelihood(scores, labels, original_sequence_lengths)\n","\n","loss = tf.reduce_mean(-log_likelihood)\n","\n","losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=scores, labels=labels)\n","# shape = (batch, sentence, nclasses)\n","mask = tf.sequence_mask(original_sequence_lengths)\n","# apply mask\n","losses = tf.boolean_mask(losses, mask)\n","\n","loss = tf.reduce_mean(losses)\n","# Compute the viterbi sequence and score (used for prediction and test time).\n","viterbi_sequence, viterbi_score = tf.contrib.crf.crf_decode(scores, transition_params, original_sequence_lengths)\n","\n","# Training ops.\n","optimizer = tf.train.AdamOptimizer(learning_rate)\n","train_op = optimizer.minimize(loss)\n","\n","# Add ops to save and restore all the variables.\n","saver = tf.train.Saver()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"}]},{"metadata":{"id":"FHyPkSHKbu_w","colab_type":"code","outputId":"a5220c12-f93c-4ec4-ce6e-ddc2dc4df467","executionInfo":{"status":"ok","timestamp":1541704804454,"user_tz":-420,"elapsed":1069905,"user":{"displayName":"Syaoran Clone","photoUrl":"https://lh5.googleusercontent.com/-z50jZxTK8Js/AAAAAAAAAAI/AAAAAAAAADM/pUn0TaeAECU/s64/photo.jpg","userId":"11466975508847902953"}},"colab":{"base_uri":"https://localhost:8080/","height":562}},"cell_type":"code","source":["with tf.Session() as session:\n","    session.run(tf.global_variables_initializer())\n","    for i in range(training_epochs):\n","        for batch_data,batch_labels,max_sequence_length,batch_sequence_lengths in batch(data=x_trains,labels=y_trains,\n","                                                                                        batch_size=batch_size,\n","                                                                                        sequence_length=list_sequence_length_train):\n","            if(batch_data.shape != (0,)):\n","                tf_viterbi_sequence,_ = session.run([viterbi_sequence,train_op],\n","                                                    feed_dict={input_data:batch_data,\n","                                                               labels:batch_labels,\n","                                                               batch_sequence_length:max_sequence_length,\n","                                                               original_sequence_lengths:batch_sequence_lengths})\n","        if i% 10 ==0:\n","                # Create a mask to fix input lengths.\n","                total_labels = np.sum(batch_sequence_lengths)\n","                mask = (np.expand_dims(np.arange(150), axis=0) <\n","                    np.expand_dims(batch_sequence_lengths, axis=1))\n","                correct_labels = np.sum((batch_labels == tf_viterbi_sequence) * mask)\n","                accuracy = 100.0 * correct_labels / float(total_labels)\n","                print(\"Epoch: %d\" % i, \"Accuracy: %.2f%%\" % accuracy)\n","        \n","    print(\"Test Accuracy: %.2f%%\" % )\n","    \n","    print(\"Finished\")\n","            \n","        "],"execution_count":0,"outputs":[{"output_type":"stream","text":["[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 0 Accuracy: 87.65%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 10 Accuracy: 88.34%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 20 Accuracy: 89.37%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 30 Accuracy: 91.08%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 40 Accuracy: 90.05%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 50 Accuracy: 90.39%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 60 Accuracy: 90.39%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 70 Accuracy: 90.57%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 80 Accuracy: 90.39%\n","[20 31 35 36 19 22 24 32  1  7  2 21 13 10 14 19 23 17 17 16 16 10 21 19\n","  7  1  8  2  5 39 33 43]\n","Epoch: 90 Accuracy: 90.05%\n","Finished\n"],"name":"stdout"}]},{"metadata":{"id":"0FJOhUS-h3vI","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}